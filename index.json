[
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/",
	"title": "AWS Service Catalog Tools Intro Workshop",
	"tags": [],
	"description": "",
	"content": "Welcome Builders! In this workshop, we will look at how you can build on top of AWS Service Catalog using a set of open source tools to create products that address security and governance requirements. You will learn how to quickly turn a requirements into technical controls that you can demonstrate to security and governance teams within your organization.\nYou can use the arrows to move backwards and forwards through the Workshop\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/servicecatalog.html",
	"title": "AWS Service Catalog",
	"tags": [],
	"description": "",
	"content": "What is AWS Service Catalog? AWS Service Catalog Service allows organizations to create and manage catalogs of IT services that are approved for use on AWS.\nThese IT services can include everything from virtual machine images, servers, software, and databases to complete multi-tier application architectures. AWS Service Catalog allows you to centrally manage commonly deployed IT services, and helps you achieve consistent governance and meet your compliance requirements, while enabling users to quickly deploy only the approved IT services they need.\n NOTE: Whilst this Workshop makes use of AWS Service Catalog, the primary goal is to learn how to use a suite of open source tools created to compliment the native AWS service.\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet/20-bootstrapping/10-puppet-account.html",
	"title": "Puppet account",
	"tags": [],
	"description": "",
	"content": "Navigate to CloudFormation  Select the AWS CloudFormation service.    Confirm you are in the eu-west-1 (Ireland) region.\n Create a new AWS CloudFormation stack  Select \u0026lsquo;Create Stack\u0026rsquo;    Note that the Factory Initialization Stack has been deployed. If yours has not refer to \u0026lsquo;Install Factory Process\u0026rsquo;\n Select the pre-configured AWS CloudFormation template Service Catalog Puppet can be installed via a pre-created AWS CloudFormation template stored in Amazon S3 under the following URL:\n https://service-catalog-tools.s3.eu-west-2.amazonaws.com/puppet/latest/servicecatalog-puppet-initialiser.template.yaml\n  Paste this URL under \u0026lsquo;Amazon S3 URL\u0026rsquo;: Hit Next    Specify AWS CloudFormation stack details  Specify the AWS CloudFormation stack details as follows:  Stack Name: puppet-initialization-stack Enable Regions: eu-west-1 OrgIAMRoleArn: None ShouldCollectCloudformationEvents: false ShouldForwardEventsToEventbridge: false ShouldForwardFailuresToOpscenter: false   Hit Next    Create the AWS CloudFormation stack  Leave Defaults for \u0026lsquo;Configure Stack Options\u0026rsquo; Hit Next Acknowledge that the Stack will create an IAM Role Hit \u0026lsquo;Create Stack\u0026rsquo;     You will now see the stack status as CREATE_IN_PROGRESS     Wait for the stack status to go to CREATE_COMPLETE    What have we deployed? The following AWS resources have just been deployed into your AWS Account:\nAWS CloudFormation stacks The AWS CodeBuild job created two AWS CloudFormation stacks which in turn deployed the resources listed below\n URL: https://eu-west-1.console.aws.amazon.com/cloudformation/home?region=eu-west-1\n   Puppet AWS CodeCommit repository This respository holds the Service Catalog Puppet manifest YAML file which is used to configure provisioning and sharing.\n URL: https://eu-west-1.console.aws.amazon.com/codesuite/codecommit/repositories?region=eu-west-1\n   Puppet AWS CodePipeline This AWS CodePipeline is triggered by updates to the AWS CodeCommit repository. When run, it will create the Service Catalog portfolios and products defined in the portfolio files.\n URL: https://eu-west-1.console.aws.amazon.com/codesuite/codepipeline/pipelines?region=eu-west-1\n   Amazon S3 buckets Three Amazon S3 buckets were created to store artifacts for Service Catalog Puppet.\n URL: https://s3.console.aws.amazon.com/s3/home?region=eu-west-1\n   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/multi-account-strategy/starter-framework.html",
	"title": "Starter framework",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will explain the starter multi-account framework\nStarter framework Within your AWS Organization there are two types of Organizational Units (OUs) - foundational and additional.\nThe Foundational OUs group the shared accounts needed to manage the your overall AWS environment. The areas considered foundational are security, networking and logs. Each of the AWS Accounts within the foundational OUs are grouped into production and non-production environments in order to clearly distinguish between production and non production policies.\nThe additional OUs group the accounts directly related to the software development lifecycle. This includes the accounts for development (development sandboxes, source code and continuous delivery) and the accounts for the staging process from earliest testing to production.\n  Foundational Security This OUs where the accounts for security are grouped. This OU and the accounts within it is the main responsibility of the security organization.\nLog Archive Account The log archive account would be home to AWS CloudTrail logs and other security logs. We would expect to see versioned, and encrypted Amazon S3 buckets with restrictive bucket policies and MFA on delete. There should be limited access to the account and there should be alarms on user login. The log archive account should be the single source of truth.\nRead only This account would typically be owned by the security team and used to enable security operations. It would have cross account roles for viewing / scanning resources in other accounts. It would be used for exploratory security testing.\nBreak glass This account would typically be owned by the security team and used to enable security operations. It would have cross account roles for making changes to resources in other accounts. It would be used in case of an event. It should have extremely limited access, almost never be used and have an alert on login.\nTooling This account / these accounts would typically be owned by the security team and used to enable security operations. It would would be used for tools such as AWS Guard Duty, AWS Security Hub, AWS Config aggregation or Cloud Custodian.\nThere could be more than one tooling account.\nInfrastructure Infrastructure is intended for shared infrastructure services such as networking and optionally any shared hosted infrastructure services.\nAccounts in other foundational and additional OUs should only depend on the infrastructure/prod OU accounts.\nShared Services This account / these accounts would typically host the following shared services consumed by others:\n LDAP/Active Directory Deployment tools  Golden AMI Pipeline    Network This account / these accounts would typically host the following networking services consumed by others:\n DNS Shared Services VPC  Additional The Additional OUs group the accounts directly related to the SDLC. This includes the accounts for development (development sandboxes, source code and continuous delivery) and the accounts for the staging process from earliest testing to production.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet/10-using-aws-organizations.html",
	"title": "Using AWS Organizations",
	"tags": [],
	"description": "",
	"content": "You can use Service Catalog Puppet with AWS Organizations. Using it will allow you describe all accounts within an organizational unit as a single entity. This provides a quicker way to get started and an easier way of managing multiple account environments.\nIf you do not want to use Organizations please skip to the next section of this how to.\nWhat are we going to do? When enabling AWS Organizations you will need to provision an IAM Role in the Organizations master account and you will then need to provide the ARN of that role to your puppet account as an AWS SSM parameter.\nThe role provisioned in the Organizations master account is only used to list accounts. It has no write access.\nYou can use the CLI to enable AWS Organizations.\nUsing the CLI The following steps should be executed using the Service Catalog Puppet CLI which is an application built using Python 3.\nIf you have not already installed the framework you can do so by following these steps:\nIt is good practice to install Python libraries in isolated environments.\nYou can create the a virtual environment using the following command:\nvirtualenv --python=python3.7 venv source venv/bin/activate Once you have decided where to install the library you can install the package:\npip install aws-service-catalog-puppet This will install the library and all of the dependencies.\nCreating the PuppetOrgRoleForExpands IAM Role You should export the credentials for your organizations master account or set your profile so that AWS CLI commands will execute as a role in your organization master account.\nThen you can run the following command:\nservicecatalog-puppet bootstrap-org-master \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; Ensure you replace \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; with the account id of the account you will be using as your puppet account. Please note you can have multiple puppet accounts in your organization.\nRunning this command will return an ARN. This ARN should be used when setting the Org IAM role ARN.\nSetting the Org IAM role ARN You should export the credentials for your puppet account or set your profile so that AWS CLI commands will execute as a role in your puppet account.\nservicecatalog-puppet set-org-iam-role-arn \u0026lt;THE_ARN_YOU_WANT_TO_USE\u0026gt; Ensure you replace \u0026lt;THE_ARN_YOU_WANT_TO_USE\u0026gt; with the ARN returned when you created the PuppetOrgRoleForExpands\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/tools.html",
	"title": "Service Catalog Tools",
	"tags": [],
	"description": "",
	"content": " What are the Service Catalog Tools The Service Catalog Tools are a collection of open source tools authored to accelerate your use as AWS Service Catalog.\nTo find out more about the tools please read through the following:\nWhat is Service Catalog Factory Service Catalog Factory is part of a suite of open source tools which have been built to complement the AWS Service Catalog Service.\nService Catalog Factory enables you to quickly build AWS CodePipelines that will create AWS Service Catalog portfolios and populate them with products across multiple regions of your AWS Account. You specify where in git the source code is for your products and you specify which regions you would like your products to exist and the framework will perform all of the undifferentiated heavy lifting for you.\nIn addition, the pipelines that the framework creates can perform functional tests and static code analysis on your templates to help you with your Software Development Life-Cycle (SDLC).\nService Catalog Factory allows you to define AWS Service Catalog portfolios and products using YAML. You can version your products and specify where the source code for them can be found.\nYou can configure the framework to publish the portfolios, products and versions in every AWS Region that you specify.\nHigh level architecture diagram You build products in a central hub account using AWS CodePipeline and AWS CodeBuild, you then deploy them into AWS Service Catalog in every enabled region of your hub account using AWS CodePipeline and AWS CloudFormation.\n  User interaction with the framework is via a YAML file. The YAML file contains the definition of the portfolios and products you want to manage. Updates to the YAML file in AWS CodeCommit triggers the AWS CodePipeline to manage execute the tasks required.\nWhat is Service Catalog Puppet Service Catalog Puppet is part of a suite of open source tools which have been built to complement the AWS Service Catalog Service.\nService Catalog Puppet enables you to provision AWS Service Catalog Products into multiple AWS Accounts and Regions across your AWS estate.\nThe tool reduces the operational burden of engineering a solution to support portfolio sharing and product launches across an enterprise and allows you to focus on writing the products you require to support your organization's needs.\nService Catalog Puppet makes use of a number of AWS services including AWS CodePipeline, AWS CodeBuild and AWS CloudFormation to manage this for you.\nHigh-Level Architecture Diagram You use an AWS CodeBuild project in a central hub account that provisions AWS Service Catalog Products into spoke accounts on your behalf. The framework takes care of cross-account sharing and cross region product replication for you.\n  User interaction with the framework is via a YAML file. The YAML file contains the definition of the AWS Accounts you want to manage (using tags), the portfolios you want to share and the products you want to launch.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet/20-bootstrapping.html",
	"title": "Bootstrapping",
	"tags": [],
	"description": "",
	"content": "You will need to bootstrap your puppet account so you can setup the resources needed to run Service Catalog Puppet.\nYou will also need to bootstrap spoke accounts so you can share portfolios with them and provision products into them.\n Puppet account   Single spokes   Groups of spokes   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations.html",
	"title": "Design considerations",
	"tags": [],
	"description": "",
	"content": "Following the best practices for the Service Catalog Tools will ensure you get the most out of these tools with the most minimal amount of effort.\nThe following articles will help you design your solution. It is recommended you read through each - ideally before you install the tools or start provisioning / sharing products and portfolios.\n Multi Account Strategy   Selecting a factory account   Portfolio Management   Account Tagging   Product SDLC   Using IAM and SCP Effectively   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation.html",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Prerequisites In order to install these tools you will need:\n A single AWS Account which you can log into A web browser where to access the AWS console.  You will also need to decide which account to install these tools into.\nThis account will contain the AWS CodePipelines and will need to be accessible to any accounts you would like to share products with. If you want to use the optional AWS Organizations support you will need to install the tools into an AWS Account where there is (or can be) a trust relationship with the AWS Organizations master account. You can install these tools into your master account but this is not recommended.\nBoth tools should be installed into the same region of the same account.\nTask list Here:\n Service Catalog Factory   Service Catalog Puppet   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/20-service-catalog-factory.html",
	"title": "Service Catalog Factory",
	"tags": [],
	"description": "",
	"content": "Navigate to CloudFormation  Select the AWS CloudFormation Service.    Confirm that you are in the eu-west-1 (Ireland) region.\n Create a new CloudFormation Stack  Select \u0026lsquo;Create Stack\u0026rsquo;    Select the pre-configured CloudFormation Template Service Catalog Factory can be installed via a pre-created AWS CloudFormation template stored in Amazon S3 under the following URL:\n https://service-catalog-tools.s3.eu-west-2.amazonaws.com/factory/latest/servicecatalog-factory-initialiser.template.yaml\n  Paste this URL under \u0026lsquo;Amazon S3 URL\u0026rsquo;: Hit Next    Specify Stack Details  Specify the Stack details as follows:  Stack Name: factory-initialization-stack Enable Regions: eu-west-1   Hit Next    Create the CloudFormation Stack  Leave Defaults for \u0026lsquo;Configure Stack Options\u0026rsquo; Hit Next Acknowledge that the Stack will create an IAM Role Hit \u0026lsquo;Create Stack\u0026rsquo;     You will now see the stack status as CREATE_IN_PROGRESS     Wait for the stack status to go to CREATE_COMPLETE    What have we deployed? The following AWS resources have just been deployed into your AWS Account:\nAWS CloudFormation stacks The AWS CodeBuild job created two AWS CloudFormation stacks which in turn deployed the resources listed below:\n URL: https://eu-west-1.console.aws.amazon.com/cloudformation/home?region=eu-west-1\n   Factory AWS CodeCommit repository This repository holds the Service Catalog Factory YAML files which are used to configure AWS Service Catalog portfolios and products.\n URL: https://eu-west-1.console.aws.amazon.com/codesuite/codecommit/repositories?region=eu-west-1\n   Factory AWS CodePipeline This AWS CodePipeline is triggered by updates to the AWS CodeCommit repository. When run, it will create the AWS Service Catalog portfolios and products defined in the portfolio files.\n URL: https://eu-west-1.console.aws.amazon.com/codesuite/codepipeline/pipelines?region=eu-west-1\n   Amazon S3 Buckets An Amazon S3 Bucket was created to store artifacts for Service Catalog factory.\n URL: https://s3.console.aws.amazon.com/s3/home?region=eu-west-1\n   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet/20-bootstrapping/20-single-spokes.html",
	"title": "Single spokes",
	"tags": [],
	"description": "",
	"content": "What are we going to do? You will need to bootstrap spoke accounts so you can share portfolios with them and provision products into them.\nBootstrapping a spoke account will create an AWS CloudFormation stack in it. This stack will contain the Puppet IAM Role (PuppetRole) which is needed by framework to perform actions in the spoke account.\nUsing the CLI The following steps should be executed using the Service Catalog Puppet CLI which is an application built using Python 3.7.\nIf you have not already installed the framework you can do so by following these steps:\nCreate an isolated Python environment It is good practice to install Python libraries in isolated environments.\nYou can create the a virtual environment using the following command:\nvirtualenv --python=python3.7 venv source venv/bin/activate Install the package locally Once you have decided where to install the library you can install the package:\npip install aws-service-catalog-puppet This will install the library and all of the dependencies.\nRestricting spokes The PuppetRole created by the framework has the AdministratorAccess IAM managed policy attached to it. It is reccommended that you can define an IAM Permission Boundary for the PuppetRole for any production applications of this framework.\nThe IAM Permission Boundary you provide should permit the PuppetRole to interact with AWS Service Catalog to accept shares, manage portfolios and to add, provision and terminate products. In addition the IAM Role should allow the use of AWS SNS, AWS EventBridge, AWS OpsCenter if you are making use of those features.\nIn order to use an IAM Permission Boundary you will need to append the following to your commands:\n--permission-boundary arn:aws:iam::aws:policy/AdministratorAccess There will be an example of this for each command in these how tos.\nBootstrapping a spoke You should export the credentials for the spoke account or set your profile so that AWS CLI commands will execute as a role in the spoke account.\nThen you can run the following command:\nWithout a permission boundary servicecatalog-puppet bootstrap-spoke \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt;\nWith a permission boundary servicecatalog-puppet bootstrap-spoke \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; --permission-boundary arn:aws:iam::aws:policy/AdministratorAccess\nEnsure you replace \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; with the AWS Account id of the AWS Account you will be using as your puppet account.\nBootstrapping a spoke as If you want to assume a role into the spoke from your currently active role you can use the following command.\nWithout a boundary servicecatalog-puppet bootstrap-spoke-as \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; \u0026lt;ARN_OF_ASSUMABLE_ROLE_IN_SPOKE\u0026gt;\nWith a boundary servicecatalog-puppet bootstrap-spoke-as \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; \u0026lt;ARN_OF_ASSUMABLE_ROLE_IN_SPOKE\u0026gt; --permission-boundary arn:aws:iam::aws:policy/AdministratorAccess\nThis will assume the role \u0026lt;ARN_OF_ASSUMABLE_ROLE_IN_SPOKE\u0026gt; before running boostrap-spoke. This is useful if you do not want to perform the AWS STS assume-role yourself.\nEnsure you replace \u0026lt;ACCOUNT_ID_OF_YOUR_PUPPET\u0026gt; with the account id of the account you will be using as your puppet account.\nYou can use the following AWS CloudFormation template to provision the needed role:\n# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: Apache-2.0 AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: IAM Role needed to use AWS Organizations to assume role into member AWS Accounts. Parameters: ServiceCatalogFactoryAccountId: Description: The account you will be installing AWS Service Catalog Factory into Type: String OrganizationAccountAccessRole: Description: Name of the IAM role used to access cross accounts for AWS Orgs usage Default: OrganizationAccountAccessRole Type: String Resources: RoleForBootstrappingSpokes: Type: AWS::IAM::Role Description: | IAM Role needed by the account vending machine so it can create and move accounts Properties: Path: /servicecatalog-puppet/ Policies: - PolicyName: Organizations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - sts:AssumeRole Resource: !Sub \u0026#34;arn:aws:iam::*:role/${OrganizationAccountAccessRole}\u0026#34; AssumeRolePolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Effect: \u0026#34;Allow\u0026#34; Principal: AWS: !Sub \u0026#34;arn:aws:iam::${ServiceCatalogFactoryAccountId}:root\u0026#34; Action: - \u0026#34;sts:AssumeRole\u0026#34; Outputs: RoleForBootstrappingSpokesArn: Description: The ARN for your Assumable role in root account Value: !GetAtt RoleForBootstrappingSpokes.Arn "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet/20-bootstrapping/30-groups-of-spokes.html",
	"title": "Groups of spokes",
	"tags": [],
	"description": "",
	"content": "What are we going to do? If you have enabled AWS Organizations support you may want to bootstrap all spokes within an organizational unit.\nFollowing these steps will allow you to bootstrap all AWS Accounts that exist within the same organizational unit.\nUsing the CodeBuild Project In your AWS Account you can find an AWS CodeBuild project named: servicecatalog-puppet-bootstrap-an-ou\n  Click Start Build\n  Before you select Start Build again, expand the Environment variables override section.\n  Set OU_OR_PATH to the OU path or AWS Organizational Unit ID that contains all of the spokes you want to bootstrap\n  Set IAM_ROLE_NAME to the name of the IAM Role that is assumable in the spoke accounts - this must be the same name in all accounts\n  Set IAM_ROLE_ARNS to the ARNs you want to assume before assuming before the IAM_ROLE_NAME. This is should you need to assume a role with cross account permissions.\n  Click Start Build again\n  Using the CLI The following steps should be executed using the Service Catalog Puppet CLI which is an application built using Python 3.7.\nIf you have not already installed the framework you can do so by following these steps:\nCreate an isolated Python environment It is good practice to install Python libraries in isolated environments.\nYou can create the a virtual environment using the following command:\nvirtualenv --python=python3.7 venv source venv/bin/activate Install the package locally Once you have decided where to install the library you can install the package:\npip install aws-service-catalog-puppet This will install the library and all of the dependencies.\nBootstrapping spokes in OU You should export the credentials for the account that allows you to list accounts in the org and assume an IAM Role in each of the spokes.\nThen you can run the following command:\nWithout a Permission Boundary servicecatalog-puppet bootstrap-spokes-in-ou /dev DevOpsAdminRole\nIn this example /dev is the ou path and DevOpsAdminRole is the name of the assumable role in each spoke account.\nWith a Permission Boundary servicecatalog-puppet bootstrap-spokes-in-ou /dev DevOpsAdminRole --permission-boundary arn:aws:iam::aws:policy/AdministratorAccess\nIf your current role does not allow you to list accounts in the AWS Organization or allow you to assume-role across AWS accounts you can specify an ARN of an IAM role that does. When you do so the framework will assume that IAM Role first and then perform the bootstrapping.\nservicecatalog-puppet bootstrap-spokes-in-ou /dev DevOpsAdminRole arn:aws:iam::0123456789010:role/OrgRoleThatAllowsListAndAssumeRole You can use the following AWS CloudFormation template to provision the needed role:\n# Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved. # SPDX-License-Identifier: Apache-2.0 AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: IAM Role needed to use AWS Organizations to assume role into member AWS Accounts. Parameters: ServiceCatalogFactoryAccountId: Description: The account you will be installing AWS Service Catalog Factory into Type: String OrganizationAccountAccessRole: Description: Name of the IAM role used to access cross accounts for AWS Orgs usage Default: OrganizationAccountAccessRole Type: String Resources: RoleForBootstrappingSpokes: Type: AWS::IAM::Role Description: | IAM Role needed by the account vending machine so it can create and move accounts Properties: Path: /servicecatalog-puppet/ Policies: - PolicyName: Organizations PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: - sts:AssumeRole Resource: !Sub \u0026#34;arn:aws:iam::*:role/${OrganizationAccountAccessRole}\u0026#34; AssumeRolePolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Effect: \u0026#34;Allow\u0026#34; Principal: AWS: !Sub \u0026#34;arn:aws:iam::${ServiceCatalogFactoryAccountId}:root\u0026#34; Action: - \u0026#34;sts:AssumeRole\u0026#34; Outputs: RoleForBootstrappingSpokesArn: Description: The ARN for your Assumable role in root account Value: !GetAtt RoleForBootstrappingSpokes.Arn "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/30-prerequisites.html",
	"title": "Pre-requisites",
	"tags": [],
	"description": "",
	"content": "In order to complete this workshop you will need:\n A single AWS Account which you can log into A web browser to access the AWS console  If you are taking this workshop at re:Invent 2019 you should have been given a note when you entered the workshop. This note contains all you need to log into a AWS account we have created for you.\nWe have installed the tools needed for you to get going.\n If you want to run through this workshop in your own account please check the next section titled running-yourself.\n  Running yourself   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/installation/30-service-catalog-puppet.html",
	"title": "Service Catalog Puppet",
	"tags": [],
	"description": "",
	"content": "The installation of Service Catalog Puppet can be broken in the following three steps:\n Using AWS Organizations   Bootstrapping   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use.html",
	"title": "Every day use",
	"tags": [],
	"description": "",
	"content": "Welcome builders From here you can see a list of our how to articles\nYou can use the left and right arrows to navigate\n  Creating a product   Deleting a product   Creating a portfolio   Adding a product to a portfolio   Creating a manifest   Adding an account   Provisioning a product   Sharing a portfolio   Invoking a Lambda Function   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/reinvent2019/",
	"title": "AWS re:Invent 2019",
	"tags": [],
	"description": "",
	"content": "Welcome to the Service Catalog tools workshop at re:Invent 2019. In this workshop, we will walk through using Service Catalog tools to build controls for governance. At the end of the session, we hope that you will go away with tools and techniques to help you build for security and governance requirements using AWS Service Catalog.\nHouse keeping Please check through the following to help you get started.\nWhat to do if you need help Raise your hand and a helper will be with you as soon as possible.\nMeet the Team In today's workshop you have the following team\nPresenters:\n Eamonn Faherty Jamie McKay  Workshop helpers:\n Ritesh Sinha Thivan Visvanathan Alex Nicot Charles Roberts  Lets get going When you are ready, click the right arrow to begin!\nYou can use the left and right arrows to navigate through the Workshop\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/multi-account-strategy.html",
	"title": "Multi Account Strategy",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will help you align your multi-account strategy with best practices.\nAWS Organizations AWS Organizations helps you centrally govern your environment as you grow and scale your workloads on AWS. Whether you are a growing startup or a large enterprise, AWS Organizations helps you to centrally manage billing; control access, compliance, and security; and share resources across your AWS accounts.\nUsing AWS Organizations, you can automate account creation, create groups of accounts to reflect your business needs, and apply policies for these groups for governance. You can also simplify billing by setting up a single payment method for all of your AWS accounts. Through integrations with other AWS services, you can use AWS Organizations to define central configurations and resource sharing across accounts in your organization. AWS Organizations is available to all AWS customers at no additional charge.\nGetting started You can read through the following pages to understand best practices:\n Starter framework   "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/100-task-1.html",
	"title": "Budget &amp; Cost governance",
	"tags": [],
	"description": "",
	"content": " The ask Cloud usage within Example Corp has picked up significantly and a number of teams are now using EC2 instances in innovative ways. The customer has noticed that teams are often not sure which EC2 instance types to use for their applications and this is leading to underutilized EC2 instances that are run on-demand. To bring down costs, the customer has purchased a set of EC2 reserved instances, based on common workload profiles, and we need to ensure the teams are using them for long running applications.\nTo help the customer, we will design and then deploy a control that gives them visibility into which EC2 instance types are being used within an AWS account.\nThe plan We are going to create and deploy a governance control using an AWS Config managed rule to ensure the right instance types are being used.\nYou can follow these steps to do this:\n Create the control   Provision the control   Future work will involve mandating that teams use only approved instance types. To start, we will gather data via AWS Config.\nIf you need help at any time please raise your hand.\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/100-task-1/100-create-the-control.html",
	"title": "Create the control",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n define a product with a version and a portfolio in a hub account add the source code for the product provision that product into a spoke account  The hub AWS Account is the source of truth for our AWS Service Catalog products. Spoke AWS accounts are consumers of these products, you can think of them as accounts that need governance controls applied. For this workshop, we are using the same account as both the hub and spoke for simplicity; in a multi-account setup, these could be separate AWS Accounts and Regions.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Create the control\u0026rdquo;\nDefine a product with a version and a portfolio   Navigate to the ServiceCatalogFactory CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n      Copy the following snippet into the main input field:\n Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-desired-instance-types\u0026#34; Owner: \u0026#34;budget-and-cost-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - desired-instance-type with our RIs\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to budget-and-cost-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/budget-and-cost-governance/aws-config-desired-instance-types\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-desired-instance-types\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-desired-instance-types\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34;     Set the File name to portfolios/reinvent.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    What did we just do? The YAML file we created in the CodeCommit repository told the framework to perform several actions:\n create a product named aws-config-desired-instance-types add a v1 of our product create a portfolio named cloud-engineering-governance add the product: aws-config-desired-instance-types to the portfolio: cloud-engineering-governance  Verify the change worked Once you have made your changes the ServiceCatalogFactory Pipeline should have run. If you were very quick in making the change, the pipeline may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Add the source code for our product When you configured your product version, you specified the following version:\n Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-desired-instance-types\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-desired-instance-types\u0026#34; BranchName: \u0026#34;master\u0026#34;   This tells the framework the source code for the product comes from the master branch of a CodeCommit repository of the name aws-config-desired-instance-types.\nWe now need to create the CodeCommit repository and add the AWS CloudFormation template we are going to use for our product.\n  Navigate to AWS CodeCommit\n  Click Create repository\n     Input the name aws-config-desired-instance-types     Click Create     Scroll down to the bottom of the page and hit the Create file button     Copy the following snippet into the main input field:   AWSTemplateFormatVersion: \u0026#34;2010-09-09\u0026#34; Description: \u0026#34;Create an AWS Config rule ensuring the given instance types are the only instance types used\u0026#34; Parameters: InstanceType: Type: String Description: \u0026#34;Comma separated list of EC2 instance types (for example, \u0026#39;t2.small, m4.large\u0026#39;).\u0026#34; Default: \u0026#34;t2.micro, t2.small\u0026#34; Resources: AWSConfigRule: Type: AWS::Config::ConfigRule Properties: ConfigRuleName: \u0026#34;desired-instance-type\u0026#34; Description: \u0026#34;Checks whether your EC2 instances are of the specified instance types.\u0026#34; InputParameters: instanceType: !Ref InstanceType Scope: ComplianceResourceTypes: - \u0026#34;AWS::EC2::Instance\u0026#34; Source: Owner: AWS SourceIdentifier: DESIRED_INSTANCE_TYPE     Set the File name to product.template.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n Creating that file should trigger your aws-config-desired-instance-types-v1-pipeline.\nOnce the pipeline has completed it should show the Source, Tests, Package and Deploy stages in green to indicate they have completed successfully:\n  You should see your commit message on this screen, it will help you know which version of ServiceCatalogFactory repository the pipeline is processing.\n If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog products to view your newly created version.\nYou should see the product you created listed:\n  Click on the product and verify v1 is there\n  If you cannot see your version please raise your hand for some assistance\n You have now successfully created a version for your product!\nVerify the product was added to the portfolio Now that you have verified the pipeline has run you can go to Service Catalog portfolios to view your portfolio.\n Click on reinvent-cloud-engineering-governance      Click on the product aws-config-desired-instance-types\n  Click on the version v1\n    "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/150-task-2/100-create-the-control.html",
	"title": "Create the control",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n define another product with a version and add it to the existing cloud-engineering-governance portfolio add the source code for our product provision that product into a spoke account  Step by step guide Here are the steps you need to follow to \u0026ldquo;Create the control\u0026rdquo;\nDefine a product with a version and a portfolio   Navigate to the ServiceCatalogFactory CodeCommit repository again\n  Click on portfolios\n     Click on reinvent.yaml     Click Edit     We will need to insert the following to the products section:   - Name: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - aws-config-rds-storage-encrypted\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/data-governance/aws-config-rds-storage-encrypted\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-rds-storage-encrypted\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34;    Once completed it should like look this:   Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-desired-instance-types\u0026#34; Owner: \u0026#34;budget-and-cost-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - desired-instance-type with our RIs\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to budget-and-cost-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/budget-and-cost-governance/aws-config-desired-instance-types\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-desired-instance-types\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-desired-instance-types\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; - Name: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - aws-config-rds-storage-encrypted\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/data-governance/aws-config-rds-storage-encrypted\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-rds-storage-encrypted\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34;    Set your Author name Set your Email address Set your Commit message  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    What did we just do? The YAML we pasted in the previous step told the framework to perform several actions:\n create a product named aws-config-rds-storage-encrypted add a v1 of our product add the product: aws-config-rds-storage-encrypted to the portfolio: cloud-engineering-governance  Verify that the change worked Once you have made your changes the ServiceCatalogFactory Pipeline should have run. If you were very quick, the pipeline may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Add the source code for our product When you configured your product version, you specified the following version:\n Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-rds-storage-encrypted\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; BranchName: \u0026#34;master\u0026#34;   This tells the framework the source code for the product comes from the master branch of a CodeCommit repository of the name aws-config-rds-storage-encrypted.\nWe now need to create the CodeCommit repository and add the CloudFormation template we are going to use for our product.\n  Navigate to AWS CodeCommit\n  Click Create repository\n     Input the name aws-config-rds-storage-encrypted     Click Create     Scroll down to the bottom of the page and hit the Create file button     Copy the following snippet into the main input field:   AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: \u0026#34;Create an AWS Config rule ensuring RDS instances use encrypted storage\u0026#34; Resources: AWSConfigRule: Type: AWS::Config::ConfigRule Properties: ConfigRuleName: \u0026#34;rds-storage-encrypted\u0026#34; Description: \u0026#34;Checks whether storage encryption is enabled for your RDS DB instances.\u0026#34; Scope: ComplianceResourceTypes: - \u0026#34;AWS::RDS::DBInstance\u0026#34; Source: Owner: AWS SourceIdentifier: RDS_STORAGE_ENCRYPTED     Set the File name to product.template.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n Creating that file should trigger your aws-config-rds-storage-encrypted-v1-pipeline.\nOnce the pipeline has completed it should show the Source, Package, Package and Deploy stages in green to indicate they have completed successfully:\n  You should see your commit message on this screen, it will help you know which version of ServiceCatalogFactory repository the pipeline is processing.\n If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog products to view your newly created version.\nYou should see the product you created listed:\n  Click on the product and verify v1 is there\n  If you cannot see your version please raise your hand for some assistance\n You have now successfully created a version for your product!\nVerify the product was added to the portfolio Now that you have verified the pipeline has run you can go to Service Catalog portfolios to view your portfolio.\n Click on reinvent-cloud-engineering-governance      Click on the product aws-config-rds-storage-encrypted\n  Click on the version v1\n    "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/100-creating-a-product.html",
	"title": "Creating a product",
	"tags": [],
	"description": "",
	"content": " This tutorial will walk you through \u0026ldquo;Creating a product\u0026rdquo;\nWe will assume you have:\n installed Service Catalog Factory correctly  In the tutorial you will:\n Define the product   Add the source code   During this process you will check your progress by verifying what the framework is doing.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/100-creating-a-product/100-define-the-product.html",
	"title": "Define the product",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n create a portfolio file define a product define a version for our product commit our portfolio file verify the framework has create an AWS CodePipeline for our product version  Step by step guide Here are the steps you need to follow to \u0026ldquo;Define the product\u0026rdquo;\nCreate the portfolio file We need to tell the framework that a product exists. We do that by creating a portfolio file and by describing the products details there.\nHere is how we do this:\n Navigate to the ServiceCatalogFactory CodeCommit repository Scroll down to the bottom of the page and hit the Create file button      Copy the following snippet into the main input field:\n Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-enable-config\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/governance/aws-config-enable-config\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;     Set the File name to portfolios/reinvent.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    We have just told the framework there is a product named aws-config-enable-config. This product has no versions and so it will not appear in AWS Service Catalog yet.\nCreate the version We now need to tell the framework we want to create a new version of our product.\n  Navigate to the ServiceCatalogFactory CodeCommit repository again\n  Click on portfolios\n     Click on reinvent.yaml     Click Edit      Add the following to the end of the file (be careful with your indentation):\n Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-enable-config\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-enable-config\u0026#34; BranchName: \u0026#34;master\u0026#34;     Verify the contents of your file matches this:\n Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-enable-config\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/governance/aws-config-enable-config\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-enable-config\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-enable-config\u0026#34; BranchName: \u0026#34;master\u0026#34;     Once you have updated the file fill in the fields for Author name, Email address, Commit message and hit Commit changes\n  Using a good / unique commit message will help you understand what is going on later.\n Verify the version was created Once you have made your changes the ServiceCatalogFactory Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  You should see your commit message on this screen, it will help you know which version of ServiceCatalogFactory repo the pipeline is processing.\n Now that your ServiceCatalogFactory pipeline has completed you can view the newly created pipeline: aws-config-enable-config-v1-pipeline\nYou can safely ignore the aws-config-enable-config-v1-pipeline has failed warning. For the pipeline to succeed, we need to add the source code for it to work which we will do in the next step.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/110-deleting-a-product/100-disabling-the-product-versions.html",
	"title": "Disabling the product versions",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n disable a product version  Step by step guide Here are the steps you need to follow to \u0026ldquo;Disabling the product versions\u0026rdquo;\nDisable the product version When working with other teams it is recommended that you disable a product version before you delete it. This gives teams time to react before deletion of the product. If they are dependent on the product version still they can reach out to you to inform you.\nTo disable a version you need to set its Active attribute to False. You do this by editing its definition in the portfolio yaml.\n  Navigate to the ServiceCatalogFactory CodeCommit repository\n  Click on portfolios\n      Click on the portfolio yaml containing your product\n  Click Edit\n  Add or set the attribute Active for the version you want to disable to False:\n Schema: factory-2019-04-01 Products: - Name: account-vending-machine Owner: central-it@customer.com Description: The iam roles needed for you to do your jobs Distributor: central-it-team SupportDescription: Contact us on Chime for help #central-it-team SupportEmail: central-it-team@customer.com SupportUrl: https://wiki.customer.com/central-it-team/self-service/account-iam  Tags: - Key: product-type Value: iam Versions: - Name: v1 Description: The iam roles needed for you to do your jobs Active: False  Source: Provider: CodeCommit Configuration: RepositoryName: account-vending-machine BranchName: v1     Set your Author name\n  Set your Email address\n  Set your Commit message\n  Click the Commit changes button:\n    When the framework runs the product will be disabled. This change will only affect the version of the product in your factory account. If you are using the imported product in your spoke accounts it will have affect there otherwise you will need to run service-catalog-puppet to cascade the change.\nYou can verify this by navigating to Service Catalog and checking your disabled product. It should look like:\n  "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/30-prerequisites/100-running-yourself.html",
	"title": "Running yourself",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n Enable AWS Config Install the tools Create an IAM Role  In order to run the workshop in your own account you will need to enable AWS Config and create an IAM Role named TeamRole which you must then assume in order to complete the activities.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Running yourself\u0026rdquo;\nEnable AWS Config   You should save the following into a file named enable-aws-config.template.yaml:\n AWSTemplateFormatVersion: 2010-09-09 Description: | This template creates a Config Recorder and an Amazon S3 bucket where logs are published. Resources: ConfigRole: Type: \u0026#39;AWS::IAM::Role\u0026#39; Description: The IAM role used to configure AWS Config Properties: AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: Service: - config.amazonaws.com Action: - \u0026#39;sts:AssumeRole\u0026#39; ManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSConfigRole Policies: - PolicyName: root PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: \u0026#39;s3:GetBucketAcl\u0026#39; Resource: !Sub arn:aws:s3:::${S3ConfigBucket} - Effect: Allow Action: \u0026#39;s3:PutObject\u0026#39; Resource: !Sub arn:aws:s3:::${S3ConfigBucket}/AWSLogs/${AWS::AccountId}/${AWS::Region} Condition: StringEquals: \u0026#39;s3:x-amz-acl\u0026#39;: bucket-owner-full-control - Effect: Allow Action: \u0026#39;config:Put*\u0026#39; Resource: \u0026#39;*\u0026#39; ConfigRecorder: Type: \u0026#39;AWS::Config::ConfigurationRecorder\u0026#39; DependsOn: ConfigRole Properties: Name: default RoleARN: !GetAtt ConfigRole.Arn DeliveryChannel: Type: \u0026#39;AWS::Config::DeliveryChannel\u0026#39; Properties: ConfigSnapshotDeliveryProperties: DeliveryFrequency: Six_Hours S3BucketName: !Ref S3ConfigBucket S3ConfigBucket: DeletionPolicy: Retain Description: S3 bucket with AES256 Encryption set Type: AWS::S3::Bucket Properties: BucketName: !Sub config-bucket-${AWS::AccountId} PublicAccessBlockConfiguration: BlockPublicAcls: True BlockPublicPolicy: True IgnorePublicAcls: True RestrictPublicBuckets: True BucketEncryption: ServerSideEncryptionConfiguration: - ServerSideEncryptionByDefault: SSEAlgorithm: AES256 S3ConfigBucketPolicy: Type: AWS::S3::BucketPolicy Description: S3 bucket policy Properties: Bucket: !Ref S3ConfigBucket PolicyDocument: Version: 2012-10-17 Statement: - Sid: AWSBucketPermissionsCheck Effect: Allow Principal: Service: - config.amazonaws.com Action: s3:GetBucketAcl Resource: - !Sub \u0026#34;arn:aws:s3:::${S3ConfigBucket}\u0026#34; - Sid: AWSBucketDelivery Effect: Allow Principal: Service: - config.amazonaws.com Action: s3:PutObject Resource: !Sub \u0026#34;arn:aws:s3:::${S3ConfigBucket}/AWSLogs/*/*\u0026#34; Outputs: ConfigRoleArn: Value: !GetAtt ConfigRole.Arn S3ConfigBucketArn: Value: !GetAtt S3ConfigBucket.Arn     You should then use AWS CloudFormation to create a stack named enable-aws-config using the template you just created\n  What did we just do?  You created an AWS CloudFormation template You used the template to create a stack The stack you created enabled AWS Config  Install the tools  You should save the following into a file named install-the-tools.template.yaml:   AWSTemplateFormatVersion: 2010-09-09 Description: \u0026#34;This template uses Stack Resource to install Service Catalog Factory and Puppet\u0026#34; Resources: FactoryInstall: Type: AWS::CloudFormation::Stack Properties: Parameters: EnabledRegions: eu-west-1 TemplateURL: \u0026#34;https://service-catalog-tools.s3.eu-west-2.amazonaws.com/factory/latest/servicecatalog-factory-initialiser.template.yaml\u0026#34; TimeoutInMinutes: 30 PuppetInstall: Type: AWS::CloudFormation::Stack Properties: Parameters: EnabledRegions: eu-west-1 ShouldCollectCloudformationEvents: False ShouldForwardEventsToEventbridge: False ShouldForwardFailuresToOpscenter: False TemplateURL: \u0026#34;https://service-catalog-tools.s3.eu-west-2.amazonaws.com/puppet/latest/servicecatalog-puppet-initialiser.template.yaml\u0026#34; TimeoutInMinutes: 30    You should then use AWS CloudFormation to create a stack named install-the-tools.template using the template you just created  What did we just do?  You created an AWS CloudFormation template You used the template to create a stack named install-the-tools The stack you created installed the service catalog tools with the correct configuration for the workshop to run  Create an IAM Role  You should save the following into a file named create-iam-role.template.yaml:   AWSTemplateFormatVersion: \u0026#34;2010-09-09\u0026#34; Description: | Template used to create an IAM role to be used for the service catalog tools workshop Resources: TeamRole: Type: AWS::IAM::Role Properties: RoleName: TeamRole AssumeRolePolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Effect: \u0026#34;Allow\u0026#34; Principal: AWS: !Sub \u0026#34;arn:aws:iam::${AWS::AccountId}:root\u0026#34; Action: - \u0026#34;sts:AssumeRole\u0026#34; ManagedPolicyArns: - arn:aws:iam::aws:policy/AdministratorAccess     You should then use AWS CloudFormation to create a stack named create-iam-role.template using the template you just created\n  You should then assume that role in order to start the workshop\n  What did we just do?  You created an AWS CloudFormation template You used the template to create a stack named create-iam-role You then assumed the role so you have the correct permissions needed and have the correct role name  "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/selecting-a-factory-account.html",
	"title": "Selecting a factory account",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will help you choose which AWS Account is most suitable to use for the Service Catalog Tools\nRecommended background reading? It is recommended that you have read the following:\n Multi Account Strategy  Selecting how many factory accounts to have Currently, you can only have one factory per account but you can create multiple accounts each with their own factory.\nIf multiple teams want to make use of Service Catalog Factory the recommendation is that each team have their own instance. The teams are then independent and can operate without impacting each other. There is also a separation of concerns if there is a security factory account and a networking factory account. This reduces the blast radius should there be an incident and it enables easier billing calculations.\nIf your organization has a central cloud engineering team who work to deliver the requirements of these other teams it may be easier to manage all of the provisioning from a single factory account.\nSelecting a factory account In order to select a factory account we need to consider how you are going to be using the framework.\nA common use case is where teams use the framework to build and provision security controls into accounts that are operating their customer facing applications.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/110-deleting-a-product.html",
	"title": "Deleting a product",
	"tags": [],
	"description": "",
	"content": " This tutorial will walk you through \u0026ldquo;Deleting a product\u0026rdquo;\nWe will assume you have:\n installed Service Catalog Factory correctly added a product correctly  In the tutorial you will:\n Disabling the product versions   Deleting the product   During this process you will check your progress by verifying what the framework is doing.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/150-creating-a-portfolio.html",
	"title": "Creating a portfolio",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Creating a portfolio\u0026rdquo; with a spoke account.\nWe will assume you have installed Service Catalog Puppet correctly.\nWe are going to perform the following steps:\n create a portfolio file define a product define a version for our product commit our portfolio file verify the framework has create an AWS CodePipeline for our product version  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Creating a portfolio\u0026rdquo;\nAdding the portfolio to the framework   Navigate to the ServiceCatalogFactory CodeCommit repository\n  Click on portfolios\n     Click on reinvent.yaml     Click Edit     Add the following to the end of the file (be careful with your indentation):   Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;    Verify the contents of your file matches this:   Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-enable-config\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#39;https://wiki.example.com/cloud-engineering/governance/aws-config-enable-config\u0026#39; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-enable-config\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-enable-config\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;   Once you have updated the file fill in the fields for Author name, Email address, Commit message and hit Commit changes\n  Using a good / unique commit message will help you understand what is going on later.\n Verify the portfolio was created Once you have made your changes the ServiceCatalogFactory Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  Once you have verified the pipeline has run you can go to Service Catalog portfolios to view your portfolio.\nYou should see the portfolio you just created listed:\n  You have now successfully created a portfolio!\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/150-task-2.html",
	"title": "Data governance",
	"tags": [],
	"description": "",
	"content": " The ask Example Corp now has a number of development and test workloads in AWS. Many of these workloads make use of data storage services such as Amazon RDS and Amazon S3. The customer has recently established a dedicated data governance team, who have been tasked with identifying controls for workloads that process data classified as confidential or internal-use only.\nThe data governance team has recently issued guidelines around the use of encryption for data at rest and in transit in the cloud. We have below an excerpt from the data governance standard:\n 3.1.1 All cloud data storage systems must be configured to support encryption at rest and in transit using industry supported encryption algorithms for data classified as Confidential, or Internal-Use only. For a list of approved encryption algorithms and key-lengths please see Appendix A.\n From these guidelines there are two new requirements:\n The data governance team at Example Corp wants to get visibility into resources where encryption at rest is not being used The team wants to use AWS Service Catalog to make it easy for development teams to comply with the encryption-at-rest requirement, without having to set it up themselves.  These requirements will shape the work that goes into building additional data governance controls as development teams look to use additional AWS services to store production or material data.\nThe plan We are going to create and deploy a data governance control using an AWS Config managed rule to ensure the teams are using encryption when creating an RDS instance. We will then create a self service Service Catalog product so the teams can create compliant resources.\n Create the control   Provision the control   Create the product   If you need help at any time please raise your hand.\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/180-adding-a-product-to-a-portfolio.html",
	"title": "Adding a product to a portfolio",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Adding a product to a portfolio\u0026rdquo; into a spoke account.\nWe will assume you have:\n installed Service Catalog Puppet correctly you have created a product you have created a portfolio  We are going to perform the following steps:\n add a product to a portfolio  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Adding a product to a portfolio\u0026rdquo;\nAdd the product to the portfolio   Navigate to the ServiceCatalogFactory CodeCommit repository again\n  Click on portfolios\n     Click on reinvent.yaml     Click Edit     Replace the contents of your file with this:   Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-enable-config\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/governance/aws-config-enable-config\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-enable-config\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-enable-config\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;    Take note of the highlighted lines 26 and 27. We have added a portfolio to the product.  Once you have updated the file fill in the fields for Author name, Email address, Commit message and hit Commit changes\n  Using a good / unique commit message will help you understand what is going on later.\n Verify the product was added to the portfolio Once you have made your changes the ServiceCatalogFactory Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  Once you have verified the pipeline has run you can go to Service Catalog portfolios to view your portfolio.\n Click on reinvent-cloud-engineering-governance     Click on the product aws-config-enable-config     Click on the version v1    "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/190-creating-a-manifest.html",
	"title": "Creating a manifest",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Creating a manifest\u0026rdquo;\nWe will assume you have installed Service Catalog Puppet correctly.\nWe are going to perform the following steps:\n create a manifest file  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Creating a manifest\u0026rdquo;\nCreating the manifest file   Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n    Committing the manifest file Now that we have written the manifest file we are ready to commit it.\n  Set the File name to manifest.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/192-adding-an-account.html",
	"title": "Adding an account",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Adding an account\u0026rdquo;\nWe will assume you have:\n installed Service Catalog Puppet correctly created a manifest bootstrapped a spoke  We are going to perform the following steps:\n adding an account to the manifest file  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Adding an account\u0026rdquo;\nAdding an account to the manifest file   Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Click on manifest.yaml\n  Click Edit\n      Append the following snippet to the YAML document in the main input field (be careful with your indentation):\n  Copy the following snippet into the main input field:\n accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;     Update account_id on line to show the account id of the account you have bootstrapped\n  Committing the manifest file   Set the File name to manifest.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/conclusion/",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": "What have we accomplished? We started with a set of requirements for budget, cost, and data governance and turned them into codified controls in your AWS Accounts using native AWS Services and modern software development practices.\n An AWS Config rule that helps us discover Amazon EC2 instance types in use An AWS Config rule that identifies Amazon RDS instances that do not use encryption at rest An AWS Service Catalog product that creates a curated version of Amazon Aurora that enforces encryption by default  In the workshop we used a single AWS Account and a single AWS Region to show you what's possible using open source service catalog tools and AWS Service Catalog. You can use the service catalog tools and AWS Service Catalog to provision products across AWS estates that have hundreds of AWS Accounts, in different regions based on your requirements.\nWhat's next? We recommend that you follow this workshop with further reading about service catalog factory and service catalog puppet to get a deeper understanding of how the service catalog tools work behind the scenes to easily create and provision curated AWS Service Catalog products across your organisation.\nLevel up your skills by trying out the tasks you've completed across an estate of AWS Accounts. Think about how you could fit the tools into your day-to-day workflow with AWS Service Catalog.\nFeedback Remember to provide feedback for the workshop in the re:Invent mobile app before you leave. Your feedback helps us shape the content of workshops and is important in driving future work on service catalog tools.\nIf you'd like to provide feedback about the service catalog tools or report bugs in the workshop, please use our GitHub issue tracker.\nEnjoy re:Invent!\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/portfolio-management.html",
	"title": "Portfolio Management",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will help you understand AWS Service Catalog portfolios, what they are, how they are used by the service and how you can best make use of them whilst using the Service Catalog Tools.\nWhat is a portfolio? Within AWS Service Catalog a portfolio is a logical grouping of products.\nIt makes sense to group products that provision similar or complimentary resources together, but this may not give you the flexibility you need:\n Within AWS Service Catalog you set associations at the portfolio level so by default when you grant access to a portfolio all products can be seen. Within AWS Service Catalog you can share portfolios with other accounts. You cannot share just a single product from a portfolio.  How you can make best use of them When using the Service Catalog Tools we recommend you think about how your products will be consumed. If you are going to offer a \u0026lsquo;service catalog\u0026rsquo; or build a vending machine we recommend grouping those products together into a portfolio.\nWhen using the Service Catalog Tools to provision resources into an account we recommend grouping those products into a portfolio.\nWhen you have multiple teams building products we recommend each team having their own portfolios.\nThis normally results in at least two portfolios per team:\n team a  self service offering other products   team b  self service offering other products    The teams we have worked with normally group the products into mandatory products and self service products. For example, if the team using Service Catalog Tools is a cloud engineering / CCOE team they would provision products like AWS Security Hub Enabler into an account - this would be mandatory. If the same team had some optional products like Encrypted S3 Bucket then this would go into an optional portfolio. This results in the following structure:\n team a  mandatory optional    The names of the portfolios are for you to chose as you know your audience better than we do but we have found the following names work well:\n mandatory optional vending-machine networking-self-service well-governed-vending-machine well-architected-vending-machine compulsory  If you would like to share your portfolio names raise a github issue to share\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/100-task-1/200-provision-the-control.html",
	"title": "Provision the control",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n create a manifest file with our account in it provision the product aws-config-desired-instance-types into our account  Step by step guide Here are the steps you need to follow to provision the control. In the previous task, we created an AWS Service Catalog product but it has not yet been provisioned.\nCreate a manifest file with our account in it   Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n     For the next step you will need to know your account id. To find your account id you can check the console, in the top right drop down. It is a 12 digit number. When using your account id please do not include the hyphens ('-') and do not use the angle brackets (\u0026lsquo;\u0026lt;\u0026rsquo;,\u0026lsquo;\u0026gt;\u0026rsquo;)     Copy the following snippet into the main input field and replace account_id to show your account id on the highlighted line:   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34;  name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;   it should look like the following - but with your account id on the highlighted line:\n accounts: - account_id: \u0026#34;012345678910\u0026#34;  name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;   Provision the product aws-config-desired-instance-types into a spoke account   Append the following snippet to the end of the main input field:\n launches: aws-config-desired-instance-types: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-desired-instance-types\u0026#34; version: \u0026#34;v1\u0026#34; parameters: InstanceType: default: \u0026#34;t2.medium, t2.large, t2.xlarge\u0026#34;  deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;     The CloudFormation template we used to create this product had a parameter named InstanceType. The highlighted lines show how we can use the framework to set a value for that parameter when provisioning it.\n  The main input field should look like this (remember to set your account_id):   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; launches: aws-config-desired-instance-types: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-desired-instance-types\u0026#34; version: \u0026#34;v1\u0026#34; parameters: InstanceType: default: \u0026#34;t2.medium, t2.large, t2.xlarge\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;   Committing the manifest file Now that we have written the manifest file we are ready to commit it.\n  Set the File name to manifest.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    What did we just do? The YAML file we created in the previous step told the framework to perform the following actions:\n provision a product named aws-config-desired-instance-types into each of the enabled regions of the account  When you added the following:\n launches: aws-config-desired-instance-types: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-desired-instance-types\u0026#34; version: \u0026#34;v1\u0026#34; parameters: InstanceType: default: \u0026#34;t2.medium, t2.large, t2.xlarge\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;    You told the framework to provision v1 of aws-config-desired-instance-types from the portfolio cloud-engineering-governance into every account that has the tag type:prod\n accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;   Within each account there will be a copy of the product provisioned into each of the regions listed in the regions_enabled section:\n accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags:  - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;   For this workshop, we are creating and provisioning the product into the same AWS Account, but in a multi-account setup, you might choose to create a product in a \u0026ldquo;hub\u0026rdquo; account and provision it only to \u0026ldquo;spoke\u0026rdquo; accounts.\nIn the workshop, you will only have permission to view the products in eu-west-1.\n Verifying the provisioned product Once you have made your changes the ServiceCatalogPuppet Pipeline should have run. If you were quick in making the change, the pipeline may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source, Generate and Deploy stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog provisioned products to view your provisioned product. Please note when you arrive at the provisioned product page you will need to select account from the filter by drop down in the top right:\n  If you cannot see your product please raise your hand for some assistance\n You have now successfully provisioned a product\nVerify that the AWS Config rule is enabled To see the AWS Config rule enabled, navigate to AWS Config rules. Once there you should see the following:\n  "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/150-task-2/200-provision-the-control.html",
	"title": "Provision the control",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n provision the product aws-config-rds-storage-encrypted  For this workshop, we are using the same account as both the hub and spoke for simplicity; in a multi-account setup, products that are created in a hub account could be provisioned in multiple spoke accounts.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Provision the control\u0026rdquo;\nProvision the product aws-config-rds-storage-encrypted into a spoke account   Navigate to the ServiceCatalogPuppet CodeCommit repository again\n  Click on manifest.yaml\n  Click Edit\n  Append the following snippet to the end of the main input field:\n   aws-config-rds-storage-encrypted: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;    The main input field should look like this (remember to set your account_id):   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; launches: aws-config-desired-instance-types: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-desired-instance-types\u0026#34; version: \u0026#34;v1\u0026#34; parameters: InstanceType: default: \u0026#34;t2.medium, t2.large, t2.xlarge\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34; aws-config-rds-storage-encrypted: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;   AWS Committing the manifest file Now that we have written the manifest file we are ready to commit it.\n Set your Author name Set your Email address Set your Commit message  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    What did we just do? The YAML we pasted in the previous step told the framework to perform the following actions:\n provision a product named aws-config-rds-storage-encrypted into each of the enabled regions of the account  Verifying the provisioning Once you have made your changes the ServiceCatalogPuppet Pipeline should have run. If you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source, Generate and Deploy stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog provisioned products to view your provisioned product. Please note when you arrive at the provisioned product page you will need to select account from the filter by drop down in the top right:\n  If you cannot see your product please raise your hand for some assistance\n You have now successfully provisioned a product\nVerify the AWS Config rule is enabled To see the AWS Config rule enabled, navigate to AWS Config rules. Once there you should see the following:\n  "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/200-provisioning-a-product.html",
	"title": "Provisioning a product",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Provisioning a product\u0026rdquo; into a spoke account.\nWe will assume you have:\n installed Service Catalog Puppet correctly bootstrapped a spoke you have created a product you have created a portfolio  We are going to perform the following steps:\n create a manifest file add an account to the manifest file add a launch to the manifest file  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Provisioning a product\u0026rdquo;\nCreating the manifest file   Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n    Adding an account to the manifest file   Copy the following snippet into the main input field:\n accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;     Update account_id on line to show your account id\n  Adding a launch to the manifest Now we are ready to add a product to the manifest file.\n Add the following snippet to the end of the main input field:   launches: aws-config-enable-config: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-enable-config\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;    The main input field should look like this:   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; launches: aws-config-enable-config: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-enable-config\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;   Committing the manifest file Now that we have written the manifest file we are ready to commit it.\n  Set the File name to manifest.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    Verifying the provisioning Once you have made your changes the ServiceCatalogPuppet Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  Once you have verified the pipeline has run you can go to Service Catalog provisioned products to view your provisioned product. Please note when you arrive at the provisioned product page you will need to select account from the filter by drop down in the top right:\n  You have now successfully provisioned a product! When provisioned, this product will automatically enable AWS Config.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/account-tagging.html",
	"title": "Account Tagging",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will explain how tags are used by the Service Catalog Tools and will make some recommendations on which tags you should be thinking about using.\nHow does Service Catalog Tools use account tags? When writing your manifest you can specify tags for AWS Accounts:\n accounts: - account_id: 012345678910\u0026#34; name: \u0026#34;prod-member-service-9\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;    The tags assigned to this account are type:prod and partition:eu.\nThese tags are later used in the launches and spoke-portfolio-shares sections of the manifest file to choose which AWS Accounts should have products provisioned into them and which AWS Accounts should have portfolios shared with them:\n launches: aws-config-rds-storage-encrypted: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34;  regions: \u0026#34;default_region\u0026#34; spoke-local-portfolios: cloud-engineering-self-service: portfolio: \u0026#34;reinvent-cloud-engineering-self-service\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34;  regions: \u0026#34;default_region\u0026#34;   The Service Catalog Tools looks through the launches and the spoke-local-portfolios. For each launch and spoke-local-portfolio found the framework will look through the tags specified in the tags section. For each tag found the Service Catalog Tools will look through the list of accounts for an account with the same tag. When the tag is found the product is provisioned if the tag was found in the launch section otherwise the portfolio specified will be shared if the tag was found in a spoke-local-portfolio.\nHow you can make best use of them Having the right number of tags is essential. Too few tags will cause you to have less flexibility but having too many may lead to a larger than needed manifest file or feeling overwhelmed.\nTo begin with, we recommend using foundation and additional tags to align to the multi-account strategy best practice:\n outype:foundational outype:additional  We then recommend describing which OU the AWS Accounts are in:\n ou:sharedservices ou:networking ou:securityreadonly  We then recommend the following tags based on the type of the workloads that exist in the AWS account:\n type:prod type:test type:dev type:sandbox type:suspended  We then recommend using a set of scope tags to help explain the governance needs of the accounts:\n scope:pci scope:pii scope:hipaa  We may also want to classify the account by the confidentiality of the data within it\n confidentiality:highly confidentiality:medium confidentiality:public  It may also be convenient to tag the accounts with the team or business unit:\n team:ccoe team:member-services team:mobile-banking businessunit:security  The tags you specify within the manifest are not applied to the accounts using AWS Organizations - they only exist within the manifest file. You can change them at any time and renaming them will not result in changes.\nIf you would like to share your tagging patterns raise a github issue to share\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/100-creating-a-product/300-add-the-source-code.html",
	"title": "Add the source code",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n Add the source code for the version of the AWS Service Catalog product we have just created  Step by step guide Here are the steps you need to follow to \u0026ldquo;Add the source code\u0026rdquo;\nAdd the source code for your product When you configured your product version, you specified the following:\n Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-enable-config\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-enable-config\u0026#34; BranchName: \u0026#34;master\u0026#34;   We now need to create the AWS CodeCommit repository and add the AWS CloudFormation template we are going to use for our product into that repository.\n  Navigate to AWS CodeCommit\n  Click Create repository\n     Input the name aws-config-enable-config     Click Create     Scroll down to the bottom of the page and hit the Create file button      Copy the following snippet into the main input field:\n AWSTemplateFormatVersion: 2010-09-09 Description: | This template creates a Config Recorder and an Amazon S3 bucket where logs are published. Resources: ConfigRole: Type: \u0026#39;AWS::IAM::Role\u0026#39; Description: The IAM role used to configure AWS Config Properties: AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: Service: - config.amazonaws.com Action: - \u0026#39;sts:AssumeRole\u0026#39; ManagedPolicyArns: - arn:aws:iam::aws:policy/service-role/AWSConfigRole Policies: - PolicyName: root PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: \u0026#39;s3:GetBucketAcl\u0026#39; Resource: !Sub arn:aws:s3:::${S3ConfigBucket} - Effect: Allow Action: \u0026#39;s3:PutObject\u0026#39; Resource: !Sub arn:aws:s3:::${S3ConfigBucket}/AWSLogs/${AWS::AccountId}/${AWS::Region} Condition: StringEquals: \u0026#39;s3:x-amz-acl\u0026#39;: bucket-owner-full-control - Effect: Allow Action: \u0026#39;config:Put*\u0026#39; Resource: \u0026#39;*\u0026#39; ConfigRecorder: Type: \u0026#39;AWS::Config::ConfigurationRecorder\u0026#39; DependsOn: ConfigRole Properties: Name: default RoleARN: !GetAtt ConfigRole.Arn DeliveryChannel: Type: \u0026#39;AWS::Config::DeliveryChannel\u0026#39; Properties: ConfigSnapshotDeliveryProperties: DeliveryFrequency: Six_Hours S3BucketName: !Ref S3ConfigBucket S3ConfigBucket: DeletionPolicy: Retain Description: S3 bucket with AES256 Encryption set Type: AWS::S3::Bucket Properties: BucketName: !Sub config-bucket-${AWS::AccountId} PublicAccessBlockConfiguration: BlockPublicAcls: True BlockPublicPolicy: True IgnorePublicAcls: True RestrictPublicBuckets: True BucketEncryption: ServerSideEncryptionConfiguration: - ServerSideEncryptionByDefault: SSEAlgorithm: AES256 S3ConfigBucketPolicy: Type: AWS::S3::BucketPolicy Description: S3 bucket policy Properties: Bucket: !Ref S3ConfigBucket PolicyDocument: Version: 2012-10-17 Statement: - Sid: AWSBucketPermissionsCheck Effect: Allow Principal: Service: - config.amazonaws.com Action: s3:GetBucketAcl Resource: - !Sub \u0026#34;arn:aws:s3:::${S3ConfigBucket}\u0026#34; - Sid: AWSBucketDelivery Effect: Allow Principal: Service: - config.amazonaws.com Action: s3:PutObject Resource: !Sub \u0026#34;arn:aws:s3:::${S3ConfigBucket}/AWSLogs/*/*\u0026#34; Outputs: ConfigRoleArn: Value: !GetAtt ConfigRole.Arn S3ConfigBucketArn: Value: !GetAtt S3ConfigBucket.Arn     Set the File name to product.template.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n Creating that file should trigger your aws-config-enable-config-v1-pipeline.\nOnce the pipeline has completed it should show the Source, Package and Deploy stages in green to indicate they have completed successfully:\n  You should see your commit message on this screen, it will help you know which version of ServiceCatalogFactory repository the pipeline is processing.\n Once you have verified the pipeline has run you can go to Service Catalog products to view your newly created version.\nYou should see the product you created listed:\n  Click on the product and verify v1 is there\n  You have now successfully created a version for your product!\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/40-reinvent2019/150-task-2/300-create-the-product.html",
	"title": "Create the product",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We have provisioned a detective control to look for AWS RDS Instances that have don't have encryption enabled. We can do better, and create an AWS Service Catalog product that meets the encryption requirement by default using service catalog tools. When users create a new RDS instance using this product, encryption at rest is enabled by default and no further configuration is required.\nWe are going to perform the following steps:\n define a product with a version and a portfolio add the source code for our product share that portfolio with a spoke account  Step by step guide Here are the steps you need to follow to \u0026ldquo;Create the product\u0026rdquo;\nDefine a product with a version and a portfolio   Navigate to the ServiceCatalogFactory CodeCommit repository again\n  Click on portfolios\n     Click on reinvent.yaml     Click Edit     Add the following to the products section:   - Name: \u0026#34;rds-instance\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;A compliant RDS Instance you can use that meets data governance standards\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/data-governance/rds-instance\u0026#34; Options: ShouldCFNNag: True Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of rds-instance\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;rds-instance\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-self-service\u0026#34;    Add the following to the portfolios section:   - DisplayName: \u0026#34;cloud-engineering-self-service\u0026#34; Description: \u0026#34;Portfolio containing products that you can use to ensure you meet the governance guidelines\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;    Once completed it should like look this:   Schema: factory-2019-04-01 Products: - Name: \u0026#34;aws-config-desired-instance-types\u0026#34; Owner: \u0026#34;budget-and-cost-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - desired-instance-type with our RIs\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to budget-and-cost-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/budget-and-cost-governance/aws-config-desired-instance-types\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-desired-instance-types\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-desired-instance-types\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; - Name: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;Enables AWS Config rule - aws-config-rds-storage-encrypted\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/data-governance/aws-config-rds-storage-encrypted\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of aws-config-rds-storage-encrypted\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-governance\u0026#34; - Name: \u0026#34;rds-instance\u0026#34; Owner: \u0026#34;data-governance@example.com\u0026#34; Description: \u0026#34;A compliant RDS Instance you can use that meets data governance standards\u0026#34; Distributor: \u0026#34;cloud-engineering\u0026#34; SupportDescription: \u0026#34;Speak to data-governance@example.com about exceptions and speak to cloud-engineering@example.com about implementation issues\u0026#34; SupportEmail: \u0026#34;cloud-engineering@example.com\u0026#34; SupportUrl: \u0026#34;https://wiki.example.com/cloud-engineering/data-governance/rds-instance\u0026#34; Options: ShouldCFNNag: True  Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of rds-instance\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;rds-instance\u0026#34; BranchName: \u0026#34;master\u0026#34; Portfolios: - \u0026#34;cloud-engineering-self-service\u0026#34; Portfolios: - DisplayName: \u0026#34;cloud-engineering-governance\u0026#34; Description: \u0026#34;Portfolio containing the products needed to govern AWS accounts\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34; - Key: \u0026#34;cost-center\u0026#34; Value: \u0026#34;governance\u0026#34; - DisplayName: \u0026#34;cloud-engineering-self-service\u0026#34; Description: \u0026#34;Portfolio containing products that you can use to ensure you meet the governance guidelines\u0026#34; ProviderName: \u0026#34;cloud-engineering\u0026#34; Associations: - \u0026#34;arn:aws:iam::${AWS::AccountId}:role/TeamRole\u0026#34; Tags: - Key: \u0026#34;type\u0026#34; Value: \u0026#34;governance\u0026#34; - Key: \u0026#34;creator\u0026#34; Value: \u0026#34;cloud-engineering\u0026#34;   Have a look at the highlighted lines. We are using this to turn on cfn-nag, an open source tool by Stelligent that looks for insecure configuration of resources. This will add an extra layer of governance ensuring the AWS CloudFormation templates we are using meets the quality bar set by cfn-nag.\n   Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    What did we just do? The YAML we pasted in the previous step told the framework to perform several actions:\n create a product named rds-instance add a v1 of our product create a portfolio named cloud-engineering-self-service add the product: rds-instance to the portfolio: cloud-engineering-self-service  Verify the change worked Once you have made your changes the ServiceCatalogFactory Pipeline should have run. If you were very quick, the pipeline may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Add the source code for our product When you configured your product version, you specified the following version:\n Versions: - Name: \u0026#34;v1\u0026#34; Description: \u0026#34;v1 of rds-instance\u0026#34; Active: True Source: Provider: \u0026#34;CodeCommit\u0026#34; Configuration: RepositoryName: \u0026#34;rds-instance\u0026#34; BranchName: \u0026#34;master\u0026#34;   This tells the framework the source code for the product comes from the master branch of a CodeCommit repository of the name rds-instance.\nWe now need to create the CodeCommit repository and add the AWS CloudFormation template we are going to use for our product.\n  Navigate to AWS CodeCommit\n  Click Create repository\n     Input the name rds-instance     Click Create     Scroll down to the bottom of the page and hit the Create file button     Copy the following snippet into the main input field:   AWSTemplateFormatVersion: 2010-09-09 Description: \u0026#34;RDS Storage Encrypted\u0026#34; Parameters: RdsDbMasterUsername: Description: RdsDbMasterUsername Type: String Default: someuser RdsDbMasterUserPassword: Description: RdsDbMasterUserPassword Type: String NoEcho: true RdsDbDatabaseName: Description: DbDatabaseName Type: String Default: mysql57_database Resources: VPC: Type: AWS::EC2::VPC Properties: CidrBlock: 10.0.0.0/16 EnableDnsSupport: \u0026#39;false\u0026#39; EnableDnsHostnames: \u0026#39;false\u0026#39; Subnet1: Type: AWS::EC2::Subnet Properties: VpcId: Ref: VPC CidrBlock: 10.0.0.0/24 AvailabilityZone: !Select [0, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] Subnet2: Type: AWS::EC2::Subnet Properties: VpcId: Ref: VPC CidrBlock: 10.0.1.0/24 AvailabilityZone: !Select [1, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] RdsDbSubnetGroup: Type: AWS::RDS::DBSubnetGroup Properties: DBSubnetGroupDescription: Database subnets for RDS SubnetIds: - !Ref Subnet1 - !Ref Subnet2 RdsSecurityGroup: Type: AWS::EC2::SecurityGroup Description: Used to grant access to and from the VPC Properties: VpcId: !Ref VPC GroupDescription: Allow MySQL (TCP3306) access to and from the VPC SecurityGroupIngress: - IpProtocol: tcp FromPort: 3306 ToPort: 3306 CidrIp: 10.0.0.0/32 SecurityGroupEgress: - IpProtocol: tcp FromPort: 3306 ToPort: 3306 CidrIp: 10.0.0.0/32 RdsDbClusterParameterGroup: Type: AWS::RDS::DBClusterParameterGroup Properties: Description: CloudFormation Aurora Cluster Parameter Group Family: aurora-mysql5.7 Parameters: server_audit_logging: 0 server_audit_events: \u0026#39;CONNECT,QUERY,QUERY_DCL,QUERY_DDL,QUERY_DML,TABLE\u0026#39; RdsDbCluster: Type: AWS::RDS::DBCluster Properties: DBSubnetGroupName: !Ref RdsDbSubnetGroup MasterUsername: !Ref RdsDbMasterUsername MasterUserPassword: !Ref RdsDbMasterUserPassword DatabaseName: !Ref RdsDbDatabaseName Engine: aurora-mysql VpcSecurityGroupIds: - !Ref RdsSecurityGroup DBClusterIdentifier : !Sub \u0026#39;${AWS::StackName}-dbcluster\u0026#39; DBClusterParameterGroupName: !Ref RdsDbClusterParameterGroup PreferredBackupWindow: 18:05-18:35 RdsDbParameterGroup: Type: AWS::RDS::DBParameterGroup Properties: Description: CloudFormation Aurora Parameter Group Family: aurora-mysql5.7 Parameters: aurora_lab_mode: 0 general_log: 1 slow_query_log: 1 long_query_time: 10 RdsDbInstance: Type: AWS::RDS::DBInstance Properties: DBSubnetGroupName: !Ref RdsDbSubnetGroup DBParameterGroupName: !Ref RdsDbParameterGroup Engine: aurora-mysql DBClusterIdentifier: !Ref RdsDbCluster AutoMinorVersionUpgrade: \u0026#39;true\u0026#39; PubliclyAccessible: \u0026#39;false\u0026#39; PreferredMaintenanceWindow: Thu:19:05-Thu:19:35 AvailabilityZone: !Select [0, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] DBInstanceClass: \u0026#39;db.t2.small\u0026#39;     Set the File name to product.template.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Click Commit changes\n  Using a good / unique commit message will help you understand what is going on later.\n Creating that file should trigger your rds-instance-v1-pipeline.\nOnce the pipeline has completed it should show the Source stage in green to indicate it has completed successfully but it should show the CFNNag action within the Tests stage as failing:\n  Clicking the Details link within the CFNNag box will bring you to the AWS CodeBuild project. When you scroll near to the bottom of that page you should see an error:\n·[0;31;49m| FAIL F26·[0m ·[0;31;49m|·[0m ·[0;31;49m| Resources: [\u0026#34;RdsDbCluster\u0026#34;]·[0m ·[0;31;49m| Line Numbers: [84]·[0m ·[0;31;49m|·[0m ·[0;31;49m| RDS DBCluster should have StorageEncrypted enabled·[0m CFNNag has determined you are not applying encryption to your DBCluster. This is a violation of the data governance guidelines and so we need to fix it.\n  Go to AWS CodeCommit\n  Click on the rds-instance repository\n  Click on product.template.yaml\n  Click on edit\n  Replace the contents with this:\n   AWSTemplateFormatVersion: 2010-09-09 Description: \u0026#34;RDS Storage Encrypted\u0026#34; Parameters: RdsDbMasterUsername: Description: RdsDbMasterUsername Type: String Default: someuser RdsDbMasterUserPassword: Description: RdsDbMasterUserPassword Type: String NoEcho: true RdsDbDatabaseName: Description: DbDatabaseName Type: String Default: mysql57_database Resources: VPC: Type: AWS::EC2::VPC Properties: CidrBlock: 10.0.0.0/16 EnableDnsSupport: \u0026#39;false\u0026#39; EnableDnsHostnames: \u0026#39;false\u0026#39; Subnet1: Type: AWS::EC2::Subnet Properties: VpcId: Ref: VPC CidrBlock: 10.0.0.0/24 AvailabilityZone: !Select [0, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] Subnet2: Type: AWS::EC2::Subnet Properties: VpcId: Ref: VPC CidrBlock: 10.0.1.0/24 AvailabilityZone: !Select [1, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] RdsDbSubnetGroup: Type: AWS::RDS::DBSubnetGroup Properties: DBSubnetGroupDescription: Database subnets for RDS SubnetIds: - !Ref Subnet1 - !Ref Subnet2 RdsSecurityGroup: Type: AWS::EC2::SecurityGroup Description: Used to grant access to and from the VPC Properties: VpcId: !Ref VPC GroupDescription: Allow MySQL (TCP3306) access to and from the VPC SecurityGroupIngress: - IpProtocol: tcp FromPort: 3306 ToPort: 3306 CidrIp: 10.0.0.0/32 SecurityGroupEgress: - IpProtocol: tcp FromPort: 3306 ToPort: 3306 CidrIp: 10.0.0.0/32 RdsDbClusterParameterGroup: Type: AWS::RDS::DBClusterParameterGroup Properties: Description: CloudFormation Aurora Cluster Parameter Group Family: aurora-mysql5.7 Parameters: server_audit_logging: 0 server_audit_events: \u0026#39;CONNECT,QUERY,QUERY_DCL,QUERY_DDL,QUERY_DML,TABLE\u0026#39; RdsDbCluster: Type: AWS::RDS::DBCluster Properties: DBSubnetGroupName: !Ref RdsDbSubnetGroup MasterUsername: !Ref RdsDbMasterUsername MasterUserPassword: !Ref RdsDbMasterUserPassword DatabaseName: !Ref RdsDbDatabaseName Engine: aurora-mysql VpcSecurityGroupIds: - !Ref RdsSecurityGroup DBClusterIdentifier : !Sub \u0026#39;${AWS::StackName}-dbcluster\u0026#39; DBClusterParameterGroupName: !Ref RdsDbClusterParameterGroup PreferredBackupWindow: 18:05-18:35 StorageEncrypted: True  RdsDbParameterGroup: Type: AWS::RDS::DBParameterGroup Properties: Description: CloudFormation Aurora Parameter Group Family: aurora-mysql5.7 Parameters: aurora_lab_mode: 0 general_log: 1 slow_query_log: 1 long_query_time: 10 RdsDbInstance: Type: AWS::RDS::DBInstance Properties: DBSubnetGroupName: !Ref RdsDbSubnetGroup DBParameterGroupName: !Ref RdsDbParameterGroup Engine: aurora-mysql DBClusterIdentifier: !Ref RdsDbCluster AutoMinorVersionUpgrade: \u0026#39;true\u0026#39; PubliclyAccessible: \u0026#39;false\u0026#39; PreferredMaintenanceWindow: Thu:19:05-Thu:19:35 AvailabilityZone: !Select [0, !GetAZs {Ref: \u0026#39;AWS::Region\u0026#39;}] DBInstanceClass: \u0026#39;db.t2.small\u0026#39; StorageEncrypted: True    Please observe the highlighted lines showing where we have made a change. We have added:\nStorageEncrypted: True  Set your Author name Set your Email address Set your Commit message Click Commit changes  Using a good / unique commit message will help you understand what is going on later.\n Creating that file should trigger your rds-instance-v1-pipeline.\nOnce the pipeline has completed it should show the Source and Tests stages in green to indicate they have completed successfully:\n  You should see your commit message on this screen, it will help you know which version of ServiceCatalogFactory repository the pipeline is processing.\n If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog products to view your newly created version.\nYou should see the product you created listed:\n  Click on the product and verify v1 is there\n  If you cannot see your version please raise your hand for some assistance\n You have now successfully created a version for your product!\nVerify that the product was added to the portfolio Now that you have verified the pipeline has run you can go to Service Catalog portfolios to view your portfolio.\n Click on cloud-engineering-self-service      Click on the product rds-instance\n  Click on the version v1\n    Share portfolio with a spoke account   Navigate to the ServiceCatalogPuppet CodeCommit repository again\n  Click on manifest.yaml\n  Click Edit\n     Append the following snippet to the YAML document in the main input field (be careful with your indentation):   spoke-local-portfolios: cloud-engineering-self-service: portfolio: \u0026#34;reinvent-cloud-engineering-self-service\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;    The main input field should look like this:   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; launches: aws-config-desired-instance-types: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-desired-instance-types\u0026#34; version: \u0026#34;v1\u0026#34; parameters: InstanceType: default: \u0026#34;t2.medium, t2.large, t2.xlarge\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34; aws-config-rds-storage-encrypted: portfolio: \u0026#34;reinvent-cloud-engineering-governance\u0026#34; product: \u0026#34;aws-config-rds-storage-encrypted\u0026#34; version: \u0026#34;v1\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34; spoke-local-portfolios: cloud-engineering-self-service: portfolio: \u0026#34;reinvent-cloud-engineering-self-service\u0026#34; deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;   Committing the manifest file   Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    Verifying the sharing Once you have made your changes the ServiceCatalogPuppet Pipeline should have run. If you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  If this is failing please raise your hand for some assistance\n Once you have verified the pipeline has run you can go to Service Catalog portfolios to view your shared product.\nWhen you share a portfolio the framework will decide if it should share the portfolio. If the target account is the same as the factory account it will not share the portfolio as it is not needed.\nIf you cannot see your product please raise your hand for some assistance\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/110-deleting-a-product/300-deleting-the-product.html",
	"title": "Deleting the product",
	"tags": [],
	"description": "",
	"content": " What are we going to do? We are going to perform the following steps:\n delete a product version delete a product  Step by step guide Here are the steps you need to follow to \u0026ldquo;Deleting the product\u0026rdquo;\nDelete a product version When you are ready to delete a product version you will need to edit its definition in the portfolio yaml.\n  Navigate to the ServiceCatalogFactory CodeCommit repository\n  Click on portfolios\n      Click on the portfolio yaml containing your product\n  Click Edit\n  Add or set the attribute Status for the version you want to delete to terminated:\n Schema: factory-2019-04-01 Products: - Name: account-vending-machine Owner: central-it@customer.com Description: The iam roles needed for you to do your jobs Distributor: central-it-team SupportDescription: Contact us on Chime for help #central-it-team SupportEmail: central-it-team@customer.com SupportUrl: https://wiki.customer.com/central-it-team/self-service/account-iam  Tags: - Key: product-type Value: iam Versions: - Name: v1 Description: The iam roles needed for you to do your jobs Status: terminated  Source: Provider: CodeCommit Configuration: RepositoryName: account-vending-machine BranchName: v1     Set your Author name\n  Set your Email address\n  Set your Commit message\n  Click the Commit changes button:\n    When the framework runs the product version will be deleted. This change will only affect the version of the product in your factory account. If you are using the imported product in your spoke accounts it will have affect there otherwise you will need to run service-catalog-puppet to cascade the change.\nYou can verify this by navigating to Service Catalog and checking your disabled version is removed.\nDelete a product When you are ready to delete a product you will need to edit its definition in the portfolio yaml.\n  Navigate to the ServiceCatalogFactory CodeCommit repository\n  Click on portfolios\n      Click on the portfolio yaml containing your product\n  Click Edit\n  Add or set the attribute Status for the product you want to delete to terminated:\n Schema: factory-2019-04-01 Products: - Name: account-vending-machine Status: terminated  Owner: central-it@customer.com Description: The iam roles needed for you to do your jobs Distributor: central-it-team SupportDescription: Contact us on Chime for help #central-it-team SupportEmail: central-it-team@customer.com SupportUrl: https://wiki.customer.com/central-it-team/self-service/account-iam  Tags: - Key: product-type Value: iam Versions: - Name: v1 Description: The iam roles needed for you to do your jobs Source: Provider: CodeCommit Configuration: RepositoryName: account-vending-machine BranchName: v1     Set your Author name\n  Set your Email address\n  Set your Commit message\n  Click the Commit changes button:\n    When the framework runs the product will be deleted. This change will only affect the version of the product in your factory account. If you are using the imported product in your spoke accounts it will have affect there otherwise you will need to run service-catalog-puppet to cascade the change. If you are using imported products in your spokes then the product will be deleted there.\nYou can verify this by navigating to Service Catalog and checking your disabled version is removed.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/300-sharing-a-portfolio.html",
	"title": "Sharing a portfolio",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through \u0026ldquo;Sharing a portfolio\u0026rdquo; with a spoke account.\nWe will assume you have:\n installed Service Catalog Puppet correctly bootstrapped a spoke you have created a product you have created a portfolio  We are going to perform the following steps:\n create a manifest file add an account to the manifest file add a spoke-local-portfolios to the manifest file  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Sharing a portfolio\u0026rdquo;\nCreating the manifest file   Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n    Adding an account to the manifest file We will start out by adding your account to the manifest file.\n  Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Scroll down to the bottom of the page and hit the Create file button\n      Copy the following snippet into the main input field:\n accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34;     Update account_id on line to show your account id\n  Adding spoke-local-portfolio to the manifest Now we are ready to add a product to the manifest file.\n Add the following snippet to the end of the main input field:   spoke-local-portfolios: account-vending-for-spokes: portfolio: cloud-engineering-governance-self-service deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;    The main input field should look like this:   accounts: - account_id: \u0026#34;\u0026lt;YOUR_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; spoke-local-portfolios: account-vending-for-spokes: portfolio: cloud-engineering-governance-self-service deploy_to: tags: - tag: \u0026#34;type:prod\u0026#34; regions: \u0026#34;default_region\u0026#34;   Committing the manifest file Now that we have written the manifest file we are ready to commit it.\n  Set the File name to manifest.yaml\n  Set your Author name\n  Set your Email address\n  Set your Commit message\n  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    Verifying the sharing Once you have made your changes the ServiceCatalogPuppet Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  Once you have verified the pipeline has run you can go to Service Catalog portfolios to view your shared product.\nWhen you share a portfolio the framework will decide if it should share the portfolio. If the target account is the same as the factory account it will not share the portfolio as it is not needed.\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/every-day-use/400-invoking-a-lambda-function.html",
	"title": "Invoking a Lambda Function",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This tutorial will walk you through how to use the \u0026ldquo;Invoking a Lambda Function\u0026rdquo; feature.\nWe will assume you have:\n installed Service Catalog Puppet correctly bootstrapped a spoke created a manifest file added an account to the manifest file  We are going to perform the following steps to \u0026ldquo;Invoking a Lambda Function\u0026rdquo;:\n set up an AWS IAM role in the spoke account create a sample lambda function add a lambda invoke to the manifest file  During this process you will check your progress by verifying what the framework is doing at each step.\nStep by step guide Here are the steps you need to follow to \u0026ldquo;Invoking a Lambda Function\u0026rdquo;\nSet Up an AWS IAM Role in the Spoke Account This guide assumes that a role exists within the spoke account that can be assumed by the Service Catalog Tools account. The name of this role would need to be the same across all spoke accounts, and the role would need permissions appropriate for your lambda function(s) to be able to complete its tasks. For the purpose of this example, a CloudFormation template has been provided that you can use to create the role in the spoke account that will allow our sample lambda function to run successfully.\n AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: \u0026#34;IAM Role in spoke accounts that will have trust relationship with Service Catalog Tools account.\u0026#34; Parameters: ToolsAccountId: Description: \u0026#34;The Service Catalog Tools AWS Account ID\u0026#34; Type: String ToolsAccountAccessRole: Description: \u0026#34;Name of the IAM role that the master account will be allowed to assume\u0026#34; Default: ToolsAccountAccessRole Type: String Resources: AssumedRole: Type: AWS::IAM::Role Description: | IAM Role needed by the Service Catalog Tools Account Properties: RoleName: !Ref ToolsAccountAccessRole Policies: - PolicyName: ToolsAccountTrustPolicy PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: \u0026#39;iam:*\u0026#39; Resource: \u0026#39;*\u0026#39; AssumeRolePolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Effect: \u0026#34;Allow\u0026#34; Principal: AWS: !Sub \u0026#34;arn:aws:iam::${ToolsAccountId}:root\u0026#34; Action: - \u0026#34;sts:AssumeRole\u0026#34;   Creating the sample lambda function We will need to create the AWS Lambda function that will be executed by the framework. This function will exist in the account where you have installed the Service Catalog Tools. When you want to perform an action in a spoke account you should read the account_id and region properties from the event object. If you want to use parameters they are available using the parameters attribute in the event object.\n  You should save the following into a file named create-iam-group-lambda.yaml\n AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Description: Creates a Lambda function that assumes a role into spoke accounts and creates an IAM group Resources: rLambdaCustomRole: Type: AWS::IAM::Role Properties: AssumeRolePolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Principal: Service: [lambda.amazonaws.com] Action: - sts:AssumeRole ManagedPolicyArns: - !Ref rLambdaCustomPolicy rLambdaCustomPolicy: Type: AWS::IAM::ManagedPolicy Properties: PolicyDocument: Version: 2012-10-17 Statement: - Effect: Allow Action: [\u0026#39;logs:CreateLogGroup\u0026#39;, \u0026#39;logs:CreateLogStream\u0026#39;, \u0026#39;logs:PutLogEvents\u0026#39;] Resource: !Sub arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:log-group:* - Effect: Allow Action: - sts:AssumeRole Resource: \u0026#34;*\u0026#34; rLambda: Type: AWS::Lambda::Function Properties: FunctionName: create-iam-group Description: Creates an IAM Group Handler: index.lambda_handler Code: ZipFile: | import json import boto3 # Set up clients sts = boto3.client(\u0026#39;sts\u0026#39;) def get_session_info(event): acct_id = event[\u0026#39;account_id\u0026#39;] role_name = event[\u0026#39;parameters\u0026#39;][\u0026#39;RoleName\u0026#39;] role_arn = \u0026#39;arn:aws:iam::\u0026#39; + acct_id + \u0026#39;:role/\u0026#39; + role_name sts_response = sts.assume_role( RoleArn=role_arn, RoleSessionName=\u0026#39;LambdaInvokeSession\u0026#39; ) return sts_response def lambda_handler(event, context): print(event) sts_response = get_session_info(event) access_key = sts_response[\u0026#34;Credentials\u0026#34;][\u0026#34;AccessKeyId\u0026#34;] secret_key = sts_response[\u0026#34;Credentials\u0026#34;][\u0026#34;SecretAccessKey\u0026#34;] session_token = sts_response[\u0026#34;Credentials\u0026#34;][\u0026#34;SessionToken\u0026#34;] iam = boto3.client( \u0026#39;iam\u0026#39;, aws_access_key_id=access_key, aws_secret_access_key=secret_key, aws_session_token=session_token ) group_name = \u0026#39;sc-tools-invoke-lambda-test-group\u0026#39; response = iam.create_group( GroupName=group_name ) MemorySize: 128 Role: !GetAtt rLambdaCustomRole.Arn Runtime: python3.7 Timeout: 300 Outputs: LambdaName: Value: !Ref rLambda     You should then use AWS CloudFormation to create a stack named create-iam-group-lambda using the template you just created\n  What did we just do?  You created an AWS CloudFormation template You used the template to create a stack in CloudFormation The stack created a sample lambda function  Adding a lambda-invocation to the manifest Now we are ready to add a lambda invocation to the manifest file.\n  Navigate to the ServiceCatalogPuppet CodeCommit repository\n  Click the ServiceCatalogPuppet repository\n  Click the link to the manifest.yaml file, and then click the Edit button\n  Add the following snippet to the end of the main input field:\n   lambda-invocations: create-iam-group: function_name: create-iam-group qualifier: $LATEST invocation_type: Event parameters: RoleName: default: \u0026#34;ToolsAccountAccessRole\u0026#34; invoke_for: tags: - regions: \u0026#34;default_region\u0026#34; tag: \u0026#34;type:prod\u0026#34;    The main input field should look like this:   accounts: - account_id: \u0026#34;\u0026lt;YOUR_SPOKE_ACCOUNT_ID_WITHOUT_HYPHENS\u0026gt;\u0026#34; name: \u0026#34;puppet-account\u0026#34; default_region: \u0026#34;eu-west-1\u0026#34; regions_enabled: - \u0026#34;eu-west-1\u0026#34; - \u0026#34;eu-west-2\u0026#34; tags: - \u0026#34;type:prod\u0026#34; - \u0026#34;partition:eu\u0026#34; lambda-invocations: create-iam-group: function_name: create-iam-group qualifier: $LATEST invocation_type: Event parameters: RoleName: default: \u0026#34;ToolsAccountAccessRole\u0026#34; invoke_for: tags: - regions: \u0026#34;default_region\u0026#34; tag: \u0026#34;type:prod\u0026#34;   Committing the manifest file Now that we have updated the manifest file we are ready to commit our changes.\n Set your Author name Set your Email address Set your Commit message  Using a good / unique commit message will help you understand what is going on later.\n  Click the Commit changes button:    Verifying the lambda invocation Once you have made your changes the ServiceCatalogPuppet Pipeline should have run or if you were quick may still be running. If it has not yet started feel free to the hit the Release change button.\nOnce it has completed it should show the Source and Build stages in green to indicate they have completed successfully:\n  Once you have verified the pipeline has run you can go to IAM Groups Console in the spoke account to view the IAM Group created by the lambda invoke labeled sc-tools-invoke-lambda-test-group.\n  You have now successfully invoked a lambda function!\n"
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/product-sdlc.html",
	"title": "Product SDLC",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will explain how productive teams have been structuring their AWS Accounts and how they have been managing their source code whilst working with the Service Catalog Tools.\nAWS Account structure Testing the provisioning of a single resource in AWS can be achieved using CloudFormation RSpec, awspec and others. Testing the provisioning of a single resource or even a single AWS CloudFormation stack is valuable and will give you confidence that your change will behave in the way you think without any side effects. When you have multiple developers working on the same code base, or develop over time or have different developers provisioning different stacks that must work with each other it can be difficult to manage and changes that introduce unexpected side effects can easily sneak through.\nWe do not recommend you create a whole test installation of the Service Catalog Tools for the development of products.\nThe management overhead of the installation and the complexity and delay it creates in your SDLC should be avoided and instead you should invest that effort into better automated testing so you can scale.\nWe recommend you have at least a single canary account where you can provision products that will work together. You can use actions from the Service Catalog Tools to automate the testing and promotion of products across your AWS Accounts including a mandatory provisioning into the canary account.\nManaging source code We recommend you do not modify a product version that you have shared or provisioned. If you make a change to a product then you should change the version name.\nWe have seen gitflow working well with product development. Whilst building a product the developer uses a develop branch in git. That develop version gets provisioned into the canary account for testing. Once the testing is complete the branch in merged to master and then rebranched from master to create a new version. This worked well for teams where a single developer was building a single product. If you have a product that is too big for a single developer then maybe the product needs to be split into smaller pieces. There are features in the tools that allow you split products into smaller pieces.\nIf you would like to share your SDLC process please raise a github issue to share\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/design-considerations/using-iam-and-scp-effectively.html",
	"title": "Using IAM and SCP Effectively",
	"tags": [],
	"description": "",
	"content": " What are we going to do? This article will explain how to restrict access to the AWS services for your users but still allow them to provision resources using launch constraints.\nIt will also cover how you can use resource naming conventions and conditional IAM and SCP statements to ensure users cannot modify AWS Service Catalog products or the resources within them.\nUsing launch constraints You may wish to use a service catalog to provide a set of approved resource templates for consumption. In this instance, you may want to allow consumers to provision a product that contains an AWS S3 bucket but you may not want to allow these users to provision AWS S3 buckets directly via the console or cli.\nTo achieve this, you could use a launch constraint and an IAM role assumable by the AWS Service Catalog service. The IAM role you provide as a launch constraint is used to provision the resources in the product. The role provisioning the product must have the iam:passrole permission.\nResource naming conventions along with conditional IAM and SCP statements When writing your AWS Service Catalog products you can have a parameter to all of your products that is used as a prefix to the names of the resources provisioned. You can then use IAM boundaries to prohibit the modifying of all resources that have the given prefix or you can use a conditional SCP to prohibit the modifying of all resources that have the given prefix except for the PuppetRole.\nWithin the Service Catalog Tools all provisioning occurs using an IAM role /servicecatalog-puppet/PuppetRole.\nWhen writing your products you should use globally unique parameter names to avoid clashes. If you use the same name for the resource prefixes you can set the parameter value once in the manifest file as a global parameter.\nIf you would like to share your experiences please raise a github issue\n "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/999-further_reading.html",
	"title": "Further Reading",
	"tags": [],
	"description": "",
	"content": "From here you can find out more about the Service Catalog Tools the AWS managed services used in the tutorials and workshops presented on this site.\nService Catalog Tools The following links provide more information on the open source tools used in the tutorials and workshops presented on this site:\nService Catalog Factory  Github project page for Service Catalog Factory Documentation for Service Catalog Factory  Service Catalog Puppet  Github project page for Service Catalog Puppet Documentation for Service Catalog Puppet  Shared products  We have Service Catalog products that you can use with these tools. These products perform actions like setting up multi account AWS Config or AWS Security Hub and more. You can view them on their Github project page.  AWS Services The following links provide more information on the AWS managed services used in the tutorials and workshops presented on this site:\nAWS Service Catalog  AWS Service Catalog home page  "
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aws-samples.github.io/aws-service-catalog-tools-workshop/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]